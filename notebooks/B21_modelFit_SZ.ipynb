{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit lightGBM: Liestal\n",
    "\n",
    "* Response: is_bloom \n",
    "\n",
    "* Predictors: \n",
    "    * Ca_cumsum: Cumulative chill day-based growing degree days. \n",
    "    * Cd_cumsum: Cumulative chill day-based anti-growing degree days. \n",
    "    * prcp_cumsum: Cumulated precipitation.\n",
    "    * AGDD: Accumulated growing degree days, as instructed in the usa-npn datafield description file.\n",
    "    * lat: latitude\n",
    "    * long: longitude\n",
    "    * alt: altitude\n",
    "    * month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import pickle\n",
    "\n",
    "import optuna\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "# import s3fs\n",
    "from datetime import datetime\n",
    "\n",
    "with open(\"./_config.yaml\", \"r\") as file:\n",
    "    cherry_config = yaml.safe_load(file)\n",
    "comp_data_dir = cherry_config['competition_data']\n",
    "data_dir = cherry_config['data_dir']     # data generated from A__dataPrep.ipynb\n",
    "model_dir = cherry_config['model_dir']   # output dir for the best trained lgb models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for computing Ca_cumsum and Cd_cumsum\n",
    "\n",
    "def compute_gdd(r):\n",
    "    gdd = (r[['tmax']].item() + r[['tmin']].item())/2\n",
    "    return gdd if gdd > 0 else 0\n",
    "\n",
    "\n",
    "def chill_days(r, Tc):\n",
    "    '''\n",
    "    Following Cesaraccio\n",
    "    '''\n",
    "    Tmin = r[['tmin']].item()\n",
    "    Tmax = r[['tmax']].item()\n",
    "    Tmean = (Tmin + Tmax)/2\n",
    "\n",
    "    if (0 <= Tc) & (Tc <= Tmin) & (Tmin <= Tmax):\n",
    "        Cd = 0\n",
    "        Ca = Tmean - Tc\n",
    "\n",
    "    elif (0 <= Tmin) & (Tmin <= Tc) & (Tc <= Tmax):\n",
    "        Cd = -1 * ((Tmean - Tmin) - ((Tmax - Tc)/2))\n",
    "        Ca = (Tmax - Tc)/2\n",
    "    \n",
    "    elif (0 <= Tmin) & (Tmin <= Tmax) & (Tmax <= Tc):\n",
    "        Cd = -1 * (Tmean - Tmin)\n",
    "        Ca = 0\n",
    "    \n",
    "    elif (Tmin <= 0) & (0 <= Tmax) & (Tmax <= Tc):\n",
    "        Cd = -1 * (Tmax / (Tmax - Tmin)) * (Tmax/2)\n",
    "        Ca = 0\n",
    "    \n",
    "    elif (Tmin <= 0) & (0 <= Tc) & (Tc <= Tmax):\n",
    "        Cd = -1 * ((Tmax / (Tmax - Tmin)) * (Tmax/2) - ((Tmax - Tc)/2))\n",
    "        Ca = (Tmax - Tc) / 2\n",
    "    \n",
    "    elif (Tmax < 0):\n",
    "        Cd = 0\n",
    "        Ca = 0\n",
    "    \n",
    "    else:\n",
    "        Cd = 0\n",
    "        Ca = 0\n",
    "\n",
    "    # r['Cd'] = Cd\n",
    "    # r['Ca'] = Ca\n",
    "\n",
    "    return Cd, Ca\n",
    "\n",
    "def compute_cgdd(station_df, station_id, Rc_thresh, Tc):\n",
    "\n",
    "    # Computes daily_Ca, daily_Cd, Ca_cumsum, Cd_cumsum.\n",
    "    # weather_df should have at least: tmax, tmin\n",
    "    \n",
    "    # Rc_thresh and Tc are learnt from gdd_model\n",
    "    # Rc_thresh accumulated Cd threshold to start accumulating GDD.\n",
    "    # Tc: Threshold temperature for computing Ca and Cd.\n",
    "\n",
    "    output_list = {}\n",
    "    \n",
    "    Ca_Cd_df = station_df.copy()\n",
    "    \n",
    "    Ca_Cd_df['date'] = Ca_Cd_df.apply(lambda x : \"-\".join([str(x[\"year\"]), str(x[\"month\"]), str(x[\"day\"])]), axis = 1)\n",
    "    Ca_Cd_df['date'] = pd.to_datetime(Ca_Cd_df['date'])\n",
    "    \n",
    "    Ca_Cd_df['daily_Cd'], Ca_Cd_df['daily_Ca'] = zip(*Ca_Cd_df.apply(lambda row: chill_days(row, Tc = Tc), axis = 1))\n",
    "    \n",
    "    ## Compute Ca_cumsum (a.k.a AGDD) and Cd_cumsum\n",
    "    years = Ca_Cd_df['year'].unique()\n",
    "    # years = [1992, 1993, 1994]\n",
    "    for yr in years:\n",
    "        # yr = years[1]\n",
    "        # print(yr)\n",
    "        Rc_start = datetime.strptime(str(int(yr) - 1) + \"-09-30\", \"%Y-%m-%d\")\n",
    "        \n",
    "        sub_df = Ca_Cd_df.loc[(Rc_start < Ca_Cd_df[\"date\"]) & (Ca_Cd_df[\"date\"] < datetime.strptime(str(yr)+\"-06-01\", \"%Y-%m-%d\")), :].reset_index(drop = True)\n",
    "    \n",
    "        list_id = station_id + \"-\" + str(yr)\n",
    "\n",
    "        if len(sub_df['month'].unique()) != 8:\n",
    "            # print(\"next\")\n",
    "            continue            \n",
    "\n",
    "        sub_df['Cd_cumsum'] = sub_df['daily_Cd'].cumsum()\n",
    "\n",
    "        if (np.isin(\"prcp\", sub_df.columns)):\n",
    "            sub_df[\"prcp_cumsum\"] = sub_df[\"prcp\"].cumsum()\n",
    "        \n",
    "        sub_df['Ca_cumsum'] = 0\n",
    "\n",
    "        if sub_df[sub_df['Cd_cumsum'] < Rc_thresh].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        Rc_thresh_loc = sub_df[sub_df['Cd_cumsum'] < Rc_thresh].index[0]\n",
    "\n",
    "        if pd.isna(Rc_thresh_loc):\n",
    "            Rc_thresh_loc = sub_df[sub_df['Cd_cumsum'] < Rc_thresh].index[0]\n",
    "            if pd.isna(Rc_thresh_loc):\n",
    "                continue\n",
    "\n",
    "        Rc_thresh_day = sub_df.iloc[Rc_thresh_loc]['date']\n",
    "        # print(paste0(\"reaches the Rc threshold on \", Rc_thresh_day)) # 저온요구도 달성일 i.e., 내생휴면 해제일. \n",
    "\n",
    "        if int(Rc_thresh_day.timetuple().tm_yday) > 31:\n",
    "            first_Tc_reach_day = datetime.strptime(str(yr) + \"-01-31\", \"%Y-%m-%d\")\n",
    "        else:\n",
    "            sub_df_afterRc = sub_df.iloc[range(Rc_thresh_loc, sub_df.shape[0]), :].reset_index(drop = True)\n",
    "            first_Tc_reach_loc = sub_df_afterRc[sub_df_afterRc['tmax'] > Tc].index[0]\n",
    "            first_Tc_reach_day = sub_df_afterRc.iloc[first_Tc_reach_loc]['date']\n",
    "\n",
    "        if pd.isna(first_Tc_reach_day):\n",
    "            # print(\"is na first tc reach day\")\n",
    "            continue\n",
    "        \n",
    "        first_Tc_reach_loc2 = sub_df[sub_df[\"date\"] == first_Tc_reach_day].index[0] # Ca accumulates starting this day.\n",
    "        sub_df.loc[first_Tc_reach_loc2:sub_df.shape[0], \"Ca_cumsum\"] = sub_df.loc[first_Tc_reach_loc2:sub_df.shape[0], \"daily_Ca\"].cumsum()\n",
    "        \n",
    "        # sub_df[\"diff_Ca_Cd\"] = sub_df['daily_Ca'].abs() - sub_df['daily_Cd'].abs()\n",
    "        # sub_df[\"diff_Ca_Cd_cumsum\"] = sub_df['diff_Ca_Cd'].cumsum()\n",
    "        \n",
    "        sub_df = sub_df[sub_df['month'].isin([1,2,3,4,5])].reset_index(drop=True)\n",
    "\n",
    "        sub_df['daily_gdd'] = sub_df.apply(lambda row: compute_gdd(row), axis = 1)\n",
    "        sub_df['AGDD'] = sub_df['daily_gdd'].cumsum()\n",
    "        \n",
    "        output_list[list_id] = sub_df\n",
    "\n",
    "    if len(output_list) == 0:\n",
    "        return pd.DataFrame(columns = sub_df.columns)\n",
    "    elif len(output_list) == 1:\n",
    "        out_df = output_list[list(output_list.keys())[0]].dropna().reset_index(drop = True)\n",
    "    elif len(output_list) > 1:\n",
    "        out_df = pd.concat(output_list, axis = 0).dropna().reset_index(drop = True)\n",
    "    \n",
    "\n",
    "    # return(out_df)\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "\n",
    "def generate_cgdds(temperature_df, st, Tc, Rc_thresh):\n",
    "    \n",
    "    # st = target_ids[3]\n",
    "    station_temp = temperature_df[temperature_df[\"id\"] == st]\n",
    "    city_name = station_temp.iloc[1][\"city\"]\n",
    "    # city_name\n",
    "    station_bloom_years = station_temp['year'].unique()\n",
    "     \n",
    "    sub_cds = compute_cgdd(station_df = station_temp, station_id = st, Rc_thresh = Rc_thresh, Tc=Tc)\n",
    "    \n",
    "    return sub_cds\n",
    "\n",
    "\n",
    "def generate_data(temperature_df, target_ids, Tc, Rc_thresh, pooling = False):\n",
    "    \n",
    "    args = [(temperature_df, id, Tc, Rc_thresh) for id in target_ids]\n",
    "        \n",
    "    if pooling == True:\n",
    "        n_cpus = 7\n",
    "        pool = Pool(processes = n_cpus)\n",
    "        \n",
    "        df = pd.concat(pool.starmap(generate_cgdds, args), axis = 0)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        df = pd.concat([generate_gdds(*arg) for arg in args], axis = 0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for hyperparameter tuning with Optuna\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_booster\", value=trial.user_attrs[\"best_booster\"])\n",
    "\n",
    "def train_cherry_blossom(trial):\n",
    "\n",
    "    target_vars = ['Ca_cumsum', \"Cd_cumsum\", \"AGDD\", \"lat\", \"long\", \"alt\", \"is_bloom\", \"month\", \"year\"]\n",
    "    spring_months = [3, 4, 5]\n",
    "    \n",
    "    target_set = cherry_complete.query(\"month in @spring_months\").reset_index(drop = True)\n",
    "\n",
    "    # Train-val-test split\n",
    "    test_years = list(range(2017, 2023))\n",
    "    test_set = target_set.query(\"year in @test_years\")\n",
    "    train_set = target_set.query(\"year not in @test_years\")\n",
    "    \n",
    "    # If under-sampling:\n",
    "    train_false = train_set[train_set['is_bloom'] == 0]\n",
    "    train_true = train_set[train_set['is_bloom'] == 1]\n",
    "    sample_idx = np.random.choice(range(len(train_false)), size = 2*len(train_true), replace = False)\n",
    "    train_df = pd.concat([train_false.iloc[sample_idx], train_true], axis = 0).reset_index(drop = True)[target_vars]\n",
    "\n",
    "    # If not under-sampling:\n",
    "    # train_df = train_set.copy()\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_df.drop(columns = [\"year\", \"is_bloom\"]), train_df[\"is_bloom\"], test_size = 0.2, shuffle = True, stratify=train_df[\"is_bloom\"])\n",
    "    # X_val.head()\n",
    "    dtrain = lgb.Dataset(X_train, label = y_train)\n",
    "    dval = lgb.Dataset(X_val, label = y_val)\n",
    "\n",
    "    # lgb_fit = lgb.train(\n",
    "    #     params = {\"objective\": \"binary\", \"metric\": \"binary_logloss\"},\n",
    "    #     train_set = dtrain,\n",
    "    #     valid_sets = [dtrain, dval]\n",
    "    # )\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"binary_logloss\", \"mape\"],\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        # \"num_boost_round\": 2000,\n",
    "        # \"early_stopping_round\": 400,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-8, 0.1, log = True),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    lgb_fit = lgb.train(\n",
    "        params = param,\n",
    "        train_set = dtrain,\n",
    "        valid_sets = [dval, dtrain],\n",
    "        verbose_eval=False,\n",
    "        num_boost_round = 2000,\n",
    "        callbacks = [lgb.early_stopping(stopping_rounds=400)],\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(key=\"best_booster\", value=lgb_fit)\n",
    "\n",
    "\n",
    "    def compute_mae(city, test_set):\n",
    "\n",
    "        test_set = test_set.loc[test_set['city'] == city, :].sort_values(by = \"date\")\n",
    "        test_years = test_set['year'].unique()\n",
    "        \n",
    "        errors = []\n",
    "        \n",
    "        for year in test_years:\n",
    "            # year = test_years[1]\n",
    "            pred_df = test_set.loc[test_set['year'] == year, :]\n",
    "            pred_X = pred_df.loc[:, target_vars].drop(columns = ['year', \"is_bloom\"])\n",
    "            \n",
    "            pred = lgb_fit.predict(pred_X)\n",
    "            \n",
    "            pred_df['doy'] = pred_df.loc[:, \"date\"].apply(lambda row: pd.Period(row, freq = \"D\").day_of_year)\n",
    "            max_prob = np.where(pred == np.max(pred))[0][0]\n",
    "            pred_doy = pred_df.iloc[max_prob][\"doy\"]\n",
    "            actual_doy = pred_df.loc[pred_df['is_bloom'] == True, \"doy\"].item()\n",
    "            \n",
    "            absolute_error = abs(pred_doy - actual_doy)\n",
    "            errors.append(absolute_error)\n",
    "        \n",
    "        return np.round(np.mean(errors), 3)\n",
    "\n",
    "\n",
    "    mae = compute_mae(city = \"Liestal\", test_set = test_set)\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Compute phenology features\n",
    "\n",
    "* Compute chill day-based cumulative gdd (Ca_cumsum) and AGDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing cherry_complete data has been loaded!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>prcp</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>alt</th>\n",
       "      <th>daily_Cd</th>\n",
       "      <th>daily_Ca</th>\n",
       "      <th>Cd_cumsum</th>\n",
       "      <th>prcp_cumsum</th>\n",
       "      <th>Ca_cumsum</th>\n",
       "      <th>daily_gdd</th>\n",
       "      <th>AGDD</th>\n",
       "      <th>is_bloom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GME00122710</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612414</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-114.475719</td>\n",
       "      <td>194.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GME00122710</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612414</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-114.475719</td>\n",
       "      <td>194.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GME00122710</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612414</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-114.475719</td>\n",
       "      <td>194.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GME00122710</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612414</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-114.475719</td>\n",
       "      <td>194.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GME00122710</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Merishausen</td>\n",
       "      <td>...</td>\n",
       "      <td>8.612414</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-114.475719</td>\n",
       "      <td>194.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           id  year       date  tmax  tmin  prcp  month  day  \\\n",
       "0           0  GME00122710  2011 2011-01-01  -0.5  -2.3   0.0      1    1   \n",
       "1           1  GME00122710  2011 2011-01-02  -0.2  -9.1   0.0      1    2   \n",
       "2           2  GME00122710  2011 2011-01-03  -2.9 -12.9   0.0      1    3   \n",
       "3           3  GME00122710  2011 2011-01-04  -4.2  -9.4   0.0      1    4   \n",
       "4           4  GME00122710  2011 2011-01-05  -0.9  -9.8   0.1      1    5   \n",
       "\n",
       "          city  ...      long    alt  daily_Cd  daily_Ca   Cd_cumsum  \\\n",
       "0  Merishausen  ...  8.612414  540.0       0.0       0.0 -114.475719   \n",
       "1  Merishausen  ...  8.612414  540.0       0.0       0.0 -114.475719   \n",
       "2  Merishausen  ...  8.612414  540.0       0.0       0.0 -114.475719   \n",
       "3  Merishausen  ...  8.612414  540.0       0.0       0.0 -114.475719   \n",
       "4  Merishausen  ...  8.612414  540.0       0.0       0.0 -114.475719   \n",
       "\n",
       "   prcp_cumsum  Ca_cumsum  daily_gdd  AGDD  is_bloom  \n",
       "0        194.3        0.0        0.0   0.0     False  \n",
       "1        194.3        0.0        0.0   0.0     False  \n",
       "2        194.3        0.0        0.0   0.0     False  \n",
       "3        194.3        0.0        0.0   0.0     False  \n",
       "4        194.4        0.0        0.0   0.0     False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cherry_complete_path = data_dir + \"/B21_meteoswiss_complete.csv\"\n",
    "\n",
    "if os.path.isfile(cherry_complete_path):\n",
    "    cherry_complete = pd.read_csv(cherry_complete_path)\n",
    "    print(\"existing cherry_complete data has been loaded!\")\n",
    "else:\n",
    "    temp_path = data_dir + \"/A21_meteoswiss_temperatures2.csv\"\n",
    "    temp_df = pd.read_csv(temp_path, encoding = \"latin-1\")\n",
    "\n",
    "    target_ids = [id for id in temp_df['id'].unique() if len(temp_df.loc[temp_df['id'] == id, \"year\"].unique()) > 1]\n",
    "    \n",
    "    Tc = 7 # (7 to 12)\n",
    "    Rc_thresh = -100 # (-100 to -200)\n",
    "\n",
    "    cherry_complete = generate_data(\n",
    "        temperature_df=temp_df,\n",
    "        target_ids = target_ids, \n",
    "        Tc = Tc, \n",
    "        Rc_thresh = Rc_thresh,\n",
    "        pooling = True\n",
    "    )\n",
    "    \n",
    "    cherry_complete.to_csv(cherry_complete_path)\n",
    "    print(\"new cherry_complete data has been created!\")\n",
    "\n",
    "cherry_complete['alt'] = cherry_complete['alt'].astype(float)\n",
    "cherry_complete['month'] = cherry_complete['month'].astype(int)\n",
    "cherry_complete['bloom_date'] = pd.to_datetime(cherry_complete[\"bloom_date\"])\n",
    "cherry_complete['date'] = pd.to_datetime(cherry_complete[\"date\"])\n",
    "cherry_complete[\"is_bloom\"] = cherry_complete.apply(lambda row: row['bloom_date'] == row['date'], axis = 1)\n",
    "\n",
    "cherry_complete.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c. Run hyperparameter optimization using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-28 02:59:03,072] A new study created in memory with name: no-name-6f4e278c-3151-40e1-a1e5-95412c3abe27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(\n",
    "    train_cherry_blossom, \n",
    "    n_trials=2,\n",
    "    callbacks=[callback]\n",
    "    )\n",
    "# best_model=study.user_attrs[\"best_booster\"]\n",
    "best_model=study.best_trial.user_attrs[\"best_booster\"]\n",
    "\n",
    "# save the best model\n",
    "with open(model_dir + \"/B21_lgb_liestal.pkl\", 'wb') as model:\n",
    "    pickle.dump(best_model, model)\n",
    "\n",
    "# save the study\n",
    "with open(model_dir + \"/B21_study_liestal.pkl\", 'wb') as st:\n",
    "    pickle.dump(study, st)\n",
    "\n",
    "print(\"liestal: \\n\")\n",
    "\n",
    "print(\"Number of finished trials: {} \\n\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial: \")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {} \\n\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
